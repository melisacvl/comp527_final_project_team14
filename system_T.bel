%% COMP 527 Final Project
%% Beluga mechanization for Gödel's system T 
%% Team 14: Tortoise and the Achilles

%% The goal of this tutorial is to study the extension of ordinary logic with natural numbers and recursion over natural numbers.

%%%%%%%%%%%%%%%%
%% Objectives %%
%%%%%%%%%%%%%%%%

%% Inherit natural deduction calculus 
%% Implement the natural numbers (with zero and a successor)
%% Implement primitive recursion in the same way Gödel did  
%% Implement basic arithmetic operations using primitive recursion 
%% Mechanize the meta-theoretic proof of Weak Normalization 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Defining Gödel's System T %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Defining types and terms in Gödel's System T
i : type. 

LF tp : type =
  | nat : tp        % natural number type

  | arr : tp → tp → tp
  | ⊤ : tp
  | ∧   : tp → tp → tp
  | ∨   : tp → tp → tp 
  | not  : tp → tp   
;

--prefix not 10.
--infix ∧ 6 right.
--infix ∨ 5 right.
--infix arr 4 right.

LF tm : tp → type =

  % natural numbers as a recursive type (with zero and a successor)
  | zero : tm nat                              
  | succ : tm nat → tm nat  

  %{ Primitive recursion
     It takes a natural number to recurse over and what to do in two situations: 
     1. A base case (what to return when the input is zero),
     2. A step case (what to do given the predecessor and the recursive result). 
   }%
  | prim_rec : tm nat → tm A → (tm nat → tm A → tm A) → tm A

  %{ We use step as a helper term to support the encoding of our recursive evaluation behavior when providing the meta theoretic proof of Weak Normalization
   It is not a part of System T's original syntax and is not used anywhere else like our arithmetic definitions so it doesn't interfere with our system's core logical structure.
   However, it allows us to cleanly express how recursive terms evaluate in Eval, namely for evaluating rec(succ N; base; step) = step(N, rec(N; base; step)) for Weak Normalization }%
  | step : tm nat → tm A → tm A 

  % natural deduction calculus, written in programming jargon
  | lam : (tm A → tm B) → tm (A arr B)
  | app : tm (A arr B) → tm A → tm B       

  | pair : tm A → tm B → tm  (A ∧ B)    
  | fst : tm (A ∧ B) → tm A
  | snd : tm (A ∧ B) → tm B

  | inl : tm A → tm (A ∨ B)
  | inr : tm B → tm (A ∨ B)
  | case_of : tm (A ∨ B) → (tm A → tm C) → (tm B → tm C) → tm C

  | unit : tm ⊤

  | notI : ({p:tp} tm A → tm p) → tm (not A)    
  | notE : tm (not A) → tm A → tm C     
;

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Verification of Natural Deduction %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% The following proofs are to verify that we have correctly inherited natural deduction calculus

rec nd_a : [ ⊢ tm (((A arr B) ∧ (A ∨ C)) arr (B ∨ C)) ] = [ ⊢ lam \u. (case_of (snd u) (\a. (inl (app (fst u) a))) (\c. (inr c)))];
rec nd_b : [ ⊢ tm ((A ∧ not B) arr not(A arr B))] = [ ⊢ lam \u. (notI \p. \v. (notE (snd u)) (app v (fst u)))];

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Basic Arithmetic Operations %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%% Predecesor %%%%
%{ The definition of predecesor is as follows:

pred = λ(n : nat). rec(n; z; x.y. x)

where:
- n is the number we recurse over
- rec(n; z; x.y. x) is the recursive definition which states:
  - If n = 0, return 0
  - If n = successor of some number x and y = result of recursive call on x, then return x

This means:
pred(0) = 0         % since negative numbers do not exist in System T
pred(succ(k)) = k

Therefore, in our following proof:

We have a term of the following type: (nat arr nat). 
This is because we want to the predecesor of natural number n, which is also of type natural number.

In our proof, n is our natural number input, x is the predecesor of n and r is the result of the recursion on x.
We output x, which we had already established is the predecesor of n.

}%

rec pred : [ ⊢ tm (nat arr nat)] = 
  [ ⊢ 
    lam \n.             % lambda abstraction takes nat n and applies to prim_rec
      prim_rec n        % primitive recursion over n
        zero            % base case returns 0
        (\x. \r. r)]    % step case takes predecesor x and recursive result r and returns x
;   

%%%% Addition %%%%
%{ The definition of addition is as follows: 

add = λ(m : nat). λ(n : nat). rec(m; n; x.y. s(y))

where:
- m is the number we recurse over
- n is the number we add to
- the recursive definition rec(m; n; x.y. s(y)), which states:
  - If m = 0, return n
  - If m = successor of some nat x, let y = result of recursive call on x and return successor(y)

This will give us:
add(0, n) = n
add(succ(k), n) = s(add(k, n))

Therefore, for our proof:

We have a term of the following type: ((nat ∧ nat) arr nat). 
This is because we want to add the natural numbers m and n.   
Then, we say that addition on the pair (m, n) implies the existence of another natural number, namely m+n. 

In our proof, a is the pair (m, n), x is the predecesor of m and r is the result of the recursion x+n.
We finally output the successor of r, which equivalently gives x+n+1 = (x+1)+n = m+n. 

}%

rec add : [ ⊢ tm ((nat ∧ nat) arr nat)] = 
    [ ⊢ 
      lam \a.                 % lambda abstraction takes pair (m, n)
        (prim_rec (fst a)     % primtive recursion over m
          (snd a)             % return n as base case
          (\x. \r. succ r))]  % step case takes predecesor x and recusive result r and returns succ r
;

%%%% Multiplication %%%%
%{ The definition of multiplication is as follows:

multiply = λ(m : nat). λ(n : nat). rec(m; z; x.y. add(n, y))

where:
- m is the number we recurse over, i.e. add n m times
- n is the number we add m times
- the recusive definition rec(m; z; x.y. add(n, y)), which states:
  - If m = 0, return 0
  - If m = successor of some nat x, y = the recursive result of multiply(x, n), then return add(n, y)

This gives us:
multiply(0, n) = 0
multiply(succ(k), n) = add(n, multiply(k, n))

Therefore, in our proof:

We again have a term of type: ((nat ∧ nat) arr nat). 
This is because we want to multiply the natural numbers m and n.   
Then, the multiplication on the pair (m, n) implies the existence of another natural number, namely m*n. 

In our proof, a is the pair (m, n), x is the predecesor of m, r is the result of the recursion x*n.
As we cannot call add directly, we use its definition inline with a second primitive recursion call to do: n + x*n = n + (m-1)*n = m*n.

}%

rec multiply : [ ⊢ tm ((nat ∧ nat) arr nat) ] = 
    [ ⊢ lam \a.              % lambda abstraction takes pair (m, n)
      prim_rec (fst a)       % recurse over m
        zero                 % base case returns 0
        (\x. \r.             % step case returns add(n, multiply(x, n)) for recursive result r = multiply(x, n)
          prim_rec r (snd a) (\x'. \r'. succ r'))];   % definition of add

%%%% Subtraction %%%%
%{ The definition of subtraction is as follows:

subtract = λ(m : nat). λ(n : nat) rec(n; m; x.y. pred(x))

where:
- m is the number we subtract from
- n is the number we recurse over, which is the number we subtract
- rec(n; m; x.y. pred(x)) is the recusive definition, which states:
  - If n = 0, return m
  - If n = successor of some nat x, y = the result of recursive call subtract(m, x), then return pred(y) 

This gives us:
subtract(m, 0) = m
subtract(m, succ(k)) = pred(subtract(m, k)) 

Note that subtracting a number greater than m will result in 0, since pred(0) = 0 and negative numbers do not exist in System T (since we only deal with natural numbers).

Thus, in our proof:

We again have a term of type: ((nat ∧ nat) arr nat) since the subtractaction of n from m implies the natural number m-n exists. 

In our proof, a is the pair (m, n), x is the predecesor of n, r is the result of the recursion m-x.
As we cannot call pred directly, we use its definition inline with a second primitive recursion call to do: (m - x) - 1 = m - (x+1) = m - n.

}%

rec subtract : [ ⊢ tm ((nat ∧ nat) arr nat)] = 
    [ ⊢ 
      lam \a.               % lambda abstraction takes pair (m, n)
        prim_rec (snd a)    % primitive recurse over n
          (fst a)           % return m for base case
          (\x. \r.          % return pred(subtract(m, x)) for step case for recursive result r = subtract(m, x)
            prim_rec r zero (\x'. \r'. r'))];   % definition of pred

%%%% Exponentiation %%%%
%{ The definition of exponentiation is as follows:

exp = λ(m : nat). λ(n : nat). rec(n; s(z); x y. multiply(m, y))

where:
- m is the base of the exponentiation
- n is the number we recurse over, which is the exponent
- rec(n; s(z); x y. multiply(m, y)) is the recursive definition which states:
  - If n = 0, return 1 i.e. succ(zero)
  - If n = successor of some nat x, y = the result of the recursion exp(m, x) then return multiply(m, y)

This gives us:
exp(m, 0) = 1
exp(m, succ(k)) = multiply(m, exp(m, k))

Therefore, in our proof:

We again have a term of type: ((nat ∧ nat) arr nat) since exponentiation on natural numbers m and n implies the natural number m^n exists. 

In our proof, a is the pair (m, n), x is the predecesor of n, r is the result of the recursion m-x.
As we cannot call multiply directly, we use its definition inline with a second primitive recursion call 
(which uses a third primitive recursion call for add) to do:
m * (m^k) = m^(k+1) = m^n.

}%

rec exp : [ ⊢ tm ((nat ∧ nat) arr nat) ] = 
    [ ⊢ lam \a.           % lambda abstraction takes pair (m, n)
      prim_rec (snd a)    % recurse over n
        (succ zero)       % base case returns 1
        (\x. \r.          % step case returns multiply(m, exp(m, x)) with r = exp(m, x)
          prim_rec (fst a) zero (\x'. \r'. prim_rec r x' (\x''. \r''. succ r'')))];    % definition of multiply

%%%%%%%%%%%%%%%%%%%%%%%%
%% Weak Normalization %%
%%%%%%%%%%%%%%%%%%%%%%%%

% Context schema: evaluation context for terms of System T
% We use a generic context that tracks terms with type A

schema eval_cxt = tm A;

% First, we need to define what it means to be in Normal form in System T, i.e. a fully reduced term
% We add the introduction rules for natural numbers zero and successor since these are final as well as lambda abstraction
% We do not add the elimination rule, i.e. the primitive recursion and application since it is not in Normal form as it still requires a reduction

inductive Normal : (Γ : eval_cxt) [Γ ⊢ tm A] → ctype =
  | natNorml : Normal [Γ ⊢ zero]
  | natNormr : Normal [Γ ⊢ M] → Normal [Γ ⊢ succ M]
  | lamNorm : Normal [Γ, x:tm A ⊢ M] → Normal [Γ ⊢ lam (\x. M)] % need to fix
;

% Next, we define how terms compute using Eval, which is our definition of what "reducing to" means
% This is basically our reduction relation and defines how we do the evaluation e → e'
% Then, Eval(M, N) means "term M evaluates to result N"

%{

We need to:

- be done if no more to evaluate i.e. in normal form
- evaluate if prim_rec gets the base case
- evaluate if prim_rec gets the step case
- evaluate function part of application 

For the step case, we want to match: rec(succ N; base; step) = step(N, rec(N; base; step))
What we want the Eval step to basically say is:

If M evaluates to the succ N and prim_rec N M1 M2 evaluates to the recursion result R and step M2 using N and R evaluates to final form V 
then eval prim_rec M M1 M2 will evaluate to V.

This is where our use of term step is, as explained earlier. 

}%

inductive Eval : (Γ : eval_cxt) [Γ ⊢ tm A] → [Γ ⊢ tm A] → ctype =
  | doneEval : Normal [Γ ⊢ M] → Eval [Γ ⊢ M] [Γ ⊢ M]
  | prim_recEvalBase : Eval [ Γ ⊢ M] [Γ ⊢ zero] → Eval [Γ ⊢ prim_rec M M1 (\x. \y. step x y)] [Γ ⊢ M1]
  | prim_recEvalStep : Eval [Γ ⊢ M] [Γ ⊢ succ N] → Eval [Γ ⊢ prim_rec N M1 (\x. \y. step x y)] [Γ ⊢ R] →
    Eval [Γ ⊢ step N R] [Γ ⊢ V] →  
    Eval [Γ ⊢ prim_rec M M1 (\x. \y. step x y)] [Γ ⊢ V]
  | appEval : Eval [Γ ⊢ M1] [Γ ⊢ M1'] → Eval [Γ ⊢ app M1 M2] [Γ  ⊢ app M1' M2]
;

%{ And finally, we define WN inductively:  

Main idea is that: If M evaluates to N then we can weak normalize on N,
which is effectively saying that a term is weakly normalizing if there exists some evaluation path
which leads to a normal form.

}%

inductive WN : (Γ : eval_cxt) [ Γ ⊢ tm A] → ctype =
  | doneWN : Eval [ Γ ⊢ M] [ Γ ⊢ N] → WN [Γ ⊢ N]
;

%{
As a final note, our choice of intrinsic typing helps us in our mechanization of the Weak Normalization. 
This guarantees that all terms are well-typed by construction and thus we do not have to prove type preservation separately 
and we can focus directly on evaluation behavior without worrying about type correctness.
}%